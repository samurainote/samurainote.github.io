---
title:  "Math for Machine Learning"
date:   2019-3-14
layout: single
author_profile: true
comments: true
tags:
---

*随時更新中です*

## Essential Math Topic for ML

1. Calculus 微分積分
2. Algebra 線形代数（行列・テンソル）
3. Cost Function 損失関数
4. Gradient Descent 勾配降下
5. Optimization 最適化
6. Activation Function 活性化関数

## When to use Math?

1. Algebra 代数 -> データの入力と出力を実現するため(NN)
2. Calculus 微分 -> 損失関数（最小二乗法）の計算
3. Cost Function 損失関数 -> モデルの出力と観測値の誤差の計測
4. Gradient Descent 勾配降下
5. Optimization 最適化

# 1. Calculus 微分積分

## 微分とは傾きである

　細かく変化(Δ)する事象を観察・予測するための学問

*微分は、ある物理現象やビジネスにおいて、最大値や最小値を観察・特定できる*

- 最適化
  - 最小化: 損失やコストを最小化する場面
  - 最大化: 利益や利用回数を最大化する場面

導関数の「傾き=0」となるθがポイント.

## 積分とは面積である

　一定期間における変化の合計を観察するための学問.
  *人生は積分である by はなお*

## 機械学習のゴールは「関数」づくり
*Y = F(X, θ)*     

　機械学習では主に、モデルの出力と観測値の誤差を最小化するために損失関数が用いられる

### 関数とは何か
- ボックス（ブラックボックス）
- 変換装置
- 入力と出力の間の関係を表すもの

### グラフとは何か

- 関数による入力と出力の関係を可視化したもの
- 縦軸: 出力
- 横軸: 入力  

## モデル(回帰式)
*Y = wX + b*    

- Y: 従属変数
- X: 独立変数
- w: 重み（パラメータ）
- b: バイアス

- 非線形（等速ではない）な関数作りそのものに関わるのが微分積分
- X, Yの次元に注目したのが線形代数
- 損失関数も微分積分の一部

## モデルの評価(微分)
*E = h(θ)*      

- X: 独立変数
- w: 重み（パラメータ）
- b: バイアス




## References

- [Multivariable Calculus - MIT open coursese](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/)
- [中学数学からはじめる微分積分](https://www.youtube.com/watch?v=4p1rwfXbCoY)
